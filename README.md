# ğŸ‡¹ğŸ‡· BÃ¼yÃ¼k Dil Modelleri TÃ¼rkÃ§e Benchmark Koleksiyonu

[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![Python 3.8+](https://img.shields.io/badge/python-3.8+-blue.svg)](https://www.python.org/downloads/)
[![HuggingFace](https://img.shields.io/badge/ğŸ¤—-Hugging%20Face-orange)](https://huggingface.co/datasets/alibayram)
[![arXiv](https://img.shields.io/badge/arXiv-2501.00593-b31b1b.svg)](https://arxiv.org/abs/2501.00593)
[![DOI](https://img.shields.io/badge/DOI-10.57967%2Fhf%2F3128-blue)](https://doi.org/10.57967/hf/3128)
[![Live Results](https://img.shields.io/badge/Live%20Results-magibu.web.app-green)](https://magibu.web.app/benchmarks)

**Setting Standards in Turkish NLP: TR-MMLU for Large Language Model Evaluation**

_Resmi arXiv makalesi: [arxiv:2501.00593](https://arxiv.org/abs/2501.00593)_

---

## ğŸ“‹ Ä°Ã§indekiler

- [ğŸ¯ Genel BakÄ±ÅŸ](#-genel-bakÄ±ÅŸ)
- [ï¿½ AraÅŸtÄ±rma ve YayÄ±n](#-araÅŸtÄ±rma-ve-yayÄ±n)
- [ï¿½ğŸš€ HÄ±zlÄ± BaÅŸlangÄ±Ã§](#-hÄ±zlÄ±-baÅŸlangÄ±Ã§)
- [ğŸ“Š Benchmark Koleksiyonu](#-benchmark-koleksiyonu)
- [ğŸ§ª Desteklenen Modeller](#-desteklenen-modeller)
- [ğŸ“ˆ GÃ¼ncel SonuÃ§lar ve Liderlik Tablosu](#-gÃ¼ncel-sonuÃ§lar-ve-liderlik-tablosu)
- [ğŸ”§ Kurulum](#-kurulum)
- [ğŸ’¡ KullanÄ±m](#-kullanÄ±m)
- [ğŸ“š Veri Setleri](#-veri-setleri)
- [ğŸ† Metodoloji](#-metodoloji)
- [ğŸ¤ KatkÄ±da Bulunma](#-katkÄ±da-bulunma)
- [ğŸ“ AlÄ±ntÄ±](#-alÄ±ntÄ±)
- [ğŸ“ Ä°letiÅŸim](#-iÌ‡letiÅŸim)
- [ğŸ“„ Lisans](#-lisans)

---

## ğŸ¯ Genel BakÄ±ÅŸ

TR-MMLU, TÃ¼rkÃ§e bÃ¼yÃ¼k dil modellerinin deÄŸerlendirilmesi iÃ§in geliÅŸtirilen kapsamlÄ± bir benchmark Ã§erÃ§evesidir. **magibu AI** araÅŸtÄ±rma grubu tarafÄ±ndan geliÅŸtirilmiÅŸ olup, **arXiv:2501.00593** makalesinde detaylandÄ±rÄ±lmÄ±ÅŸtÄ±r.

### ğŸŒŸ Temel Ã–zellikler

- **ğŸ“Š KapsamlÄ± DeÄŸerlendirme**: 280,000 soruluk havuzdan seÃ§ilen 6,200 soru
- **ğŸ“ EÄŸitim Sistemi TabanlÄ±**: TÃ¼rk eÄŸitim sisteminden gerÃ§ek sorular (KPSS, TUS, AUZEF, YKS)
- **ğŸ”¬ Bilimsel Metodoloji**: Peer-reviewed araÅŸtÄ±rma ile desteklenen deÄŸerlendirme
- **ğŸ“ˆ CanlÄ± SonuÃ§lar**: [magibu.web.app/benchmarks](https://magibu.web.app/benchmarks) Ã¼zerinden anlÄ±k takip
- **ğŸŒ 60+ Model**: API ve aÃ§Ä±k kaynak modellerin kapsamlÄ± karÅŸÄ±laÅŸtÄ±rmasÄ±
- **ğŸ”„ SÃ¼rekli GÃ¼ncelleme**: Yeni modellerin otomatik olarak eklenmesi

---

## ğŸ“ AraÅŸtÄ±rma ve YayÄ±n

### ï¿½ Resmi Makale

**"Setting Standards in Turkish NLP: TR-MMLU for Large Language Model Evaluation"**

- **arXiv ID**: [2501.00593](https://arxiv.org/abs/2501.00593)
- **YayÄ±n Tarihi**: 31 AralÄ±k 2024
- **Yazarlar**: M. Ali Bayram, Ali Arda Fincan, Ahmet Semih GÃ¼mÃ¼ÅŸ, Banu Diri, SavaÅŸ YÄ±ldÄ±rÄ±m, Ã–ner AytaÅŸ

### ğŸ“Š AraÅŸtÄ±rma BulgularÄ±

Makalede ortaya konan temel bulgular:

- **Tokenizasyon Etkisi**: TÃ¼rkÃ§e'nin Ã§ekimli yapÄ±sÄ±nÄ±n model performansÄ±na kritik etkisi
- **Fine-tuning Stratejileri**: TÃ¼rkÃ§e Ã¶zelleÅŸmiÅŸ modellerin genel modellere gÃ¶re performansÄ±
- **KÃ¼ltÃ¼rel BaÄŸlam**: TÃ¼rk eÄŸitim sistemine uygun deÄŸerlendirme Ã§erÃ§evesi
- **Tekrarlanabilirlik**: Åeffaf metodoloji ve aÃ§Ä±k veri setleri

### ğŸ† Bilimsel KatkÄ±lar

1. **TÃ¼rkÃ§e MMLU**: TÃ¼rkÃ§e iÃ§in standardize edilmiÅŸ Ã§ok seÃ§enekli benchmark
2. **BÃ¼yÃ¼k Ã–lÃ§ekli DeÄŸerlendirme**: 60+ modelin sistematik karÅŸÄ±laÅŸtÄ±rmasÄ±
3. **Metodolojik Yenilik**: Anlamsal benzerlik tabanlÄ± cevap doÄŸrulama
4. **AÃ§Ä±k Bilim**: TÃ¼m veri, kod ve sonuÃ§larÄ±n aÃ§Ä±k paylaÅŸÄ±mÄ±

---

## ğŸš€ HÄ±zlÄ± BaÅŸlangÄ±Ã§

```bash
# Repo'yu klonlayÄ±n
git clone https://github.com/malibayram/llm-tr-benchmarks.git
cd llm-tr-benchmarks

# Gerekli paketleri yÃ¼kleyin
pip install -r requirements.txt

# HÄ±zlÄ± test Ã§alÄ±ÅŸtÄ±rÄ±n
python olcum.py  # Ollama modelleri iÃ§in
python ChatGPT-4o-olcum.py  # OpenAI API iÃ§in

# CanlÄ± sonuÃ§larÄ± gÃ¶rÃ¼n
open https://magibu.web.app/benchmarks
```

**ğŸ‰ Tebrikler!** TR-MMLU benchmark sistemine hoÅŸ geldiniz!

---

## ğŸ“Š Benchmark Koleksiyonu

### ğŸ“ TR-MMLU Ana Benchmark

| Ã–zellik                  | Detay               |
| ------------------------ | ------------------- |
| **Toplam Soru Havuzu**   | 280,000 soru        |
| **SeÃ§ili Test SorularÄ±** | 6,200 soru          |
| **Kategori SayÄ±sÄ±**      | 62 kategori         |
| **Disiplin AlanÄ±**       | 67 farklÄ± alan      |
| **Konu BaÅŸlÄ±ÄŸÄ±**         | 800+ farklÄ± konu    |
| **Kaynak**               | TÃ¼rk EÄŸitim Sistemi |

### ğŸ“š Kategori DaÄŸÄ±lÄ±mÄ±

#### ğŸ¯ Temel EÄŸitim SÄ±navlarÄ±

- **KPSS**: Genel KÃ¼ltÃ¼r, Genel Yetenek, EÄŸitim Bilimleri
- **TUS**: TÄ±p UzmanlÄ±k SÄ±navÄ± (15 farklÄ± alan)
- **AUZEF**: AÃ§Ä±k Ã–ÄŸretim FakÃ¼ltesi (25 program)
- **YKS**: Ãœniversite GiriÅŸ SÄ±navÄ± temel konularÄ±

#### ï¿½ Bilim ve Teknoloji AlanlarÄ±

- Matematik, Fizik, Kimya, Biyoloji
- Bilgisayar Bilimleri, MÃ¼hendislik
- Ä°statistik, Astronomi, Jeoloji

#### ğŸ“– Sosyal Bilimler ve Edebiyat

- Tarih, CoÄŸrafya, Sosyoloji, Psikoloji
- TÃ¼rk Dili ve EdebiyatÄ±, Felsefe
- Hukuk, Ä°ktisat, Siyaset Bilimi

#### ğŸ¥ UzmanlÄ±k ve Meslek AlanlarÄ±

- TÄ±p ve SaÄŸlÄ±k Bilimleri
- Hukuk ve Adalet Sistemi
- EÄŸitim ve Pedagoji
- Ä°ÅŸ DÃ¼nyasÄ± ve YÃ¶netim

---

### ğŸ­ Ticari API Modelleri

#### ğŸ”¥ Premium Modeller

- **GPT-4o**: OpenAI'nin en geliÅŸmiÅŸ modeli
- **Claude-3.5-Sonnet**: Anthropic'in gÃ¼venli AI'si
- **Gemini-1.5-Pro**: Google'Ä±n multimodal modeli

#### ï¿½ Ãœcretsiz Seviye Modeller

- GÃ¼nlÃ¼k 20 istek limiti ile test
- Otomatik zamanlanmÄ±ÅŸ deÄŸerlendirme
- Firebase entegrasyonu ile takip

### ğŸ”„ Model Ekleme SÃ¼reci

#### Ollama Modelleri iÃ§in:

1. Modelinizi [ollama.com](https://ollama.com)'a yÃ¼kleyin
2. `malibayram20@gmail.com` adresine model bilgilerini gÃ¶nderin
3. Otomatik test sÃ¼reci baÅŸlatÄ±lÄ±r
4. SonuÃ§lar Hugging Face'e yÃ¼klenir

#### API Modelleri iÃ§in:

1. API endpoint ve key saÄŸlayÄ±n
2. Rate limit bilgilerini belirtin
3. Test batch'i Ã§alÄ±ÅŸtÄ±rÄ±n
4. Performans sonuÃ§larÄ± karÅŸÄ±laÅŸtÄ±rÄ±n

---

## ğŸ“ˆ GÃ¼ncel SonuÃ§lar ve Liderlik Tablosu

> **ğŸ”„ CanlÄ± SonuÃ§lar**: [magibu.web.app/benchmarks](https://magibu.web.app/benchmarks) adresinden gÃ¼ncel sonuÃ§larÄ± takip edebilirsiniz.

### ğŸ† TR-MMLU Liderlik Tablosu (Son GÃ¼ncelleme: Temmuz 2025)

| SÄ±ra | Model                       | BaÅŸarÄ± OranÄ± | DoÄŸru Cevap | Model Ailesi | Format       | Parametre | Quantization    |
| ---- | --------------------------- | ------------ | ----------- | ------------ | ------------ | --------- | --------------- |
| ğŸ¥‡   | **GPT-4o**                  | **84.84%**   | 5,260       | GPT          | API-Accessed | Unknown   | No Quantization |
| ğŸ¥ˆ   | **Claude-3.5-Sonnet**       | **84.40%**   | 5,233       | Sonnet       | API-Accessed | Unknown   | No Quantization |
| ğŸ¥‰   | **OpenAI GPT-4**            | **82.45%**   | 5,112       | GPT          | API-Accessed | Unknown   | No Quantization |
| 4    | **Llama 3.3**               | **79.42%**   | 4,924       | Llama        | GGUF         | 70.6B     | Q4_K_M          |
| 5    | **Qwen 3 (235B)**           | **78.63%**   | 103         | Qwen         | API          | 235B      | Unknown         |
| 6    | **Moonshot Kimi-K2**        | **77.94%**   | 219         | Unknown      | API          | Unknown   | Unknown         |
| 7    | **Gemini-1.5-Pro**          | **76.74%**   | 4,758       | Gemini       | API-Accessed | Unknown   | No Quantization |
| 8    | **Qwen 3 (32B)**            | **75.98%**   | 4,711       | Qwen3        | GGUF         | 32.8B     | Q4_K_M          |
| 9    | **Gemma 3 (27B)**           | **75.06%**   | 4,654       | Gemma3       | GGUF         | 27.4B     | Q4_K_M          |
| 10   | **Google Gemini-2.5-Flash** | **74.66%**   | 4,629       | Gemini       | API          | Unknown   | Unknown         |

### ğŸ‡¹ğŸ‡· TÃ¼rkÃ§e Ã–zelleÅŸmiÅŸ Modeller Top 10

| SÄ±ra | Model                                      | BaÅŸarÄ± OranÄ± | DoÄŸru Cevap | GeliÅŸtirici | Ã–zelleÅŸme AlanÄ±          |
| ---- | ------------------------------------------ | ------------ | ----------- | ----------- | ------------------------ |
| 1    | **alibayram/medgemma (27B)**               | **74.18%**   | 4,599       | Ali Bayram  | TÄ±bbi NLP                |
| 2    | **alibayram/emre-gemma3-27b-tr-reasoning** | **73.21%**   | 4,539       | Ali Bayram  | TÃ¼rkÃ§e MantÄ±ksal Ã‡Ä±karÄ±m |
| 3    | **alibayram/doktor-gemma3 (12B)**          | **71.08%**   | 4,407       | Ali Bayram  | TÄ±bbi UzmanlÄ±k           |
| 4    | **alibayram/turkish-gemma-9b-v0.1**        | **70.34%**   | 4,361       | Ali Bayram  | TÃ¼rkÃ§e Genel AmaÃ§lÄ±      |
| 5    | **alibayram/metin-gemma2-9b-it-tr-dpo-v1** | **69.16%**   | 4,288       | Ali Bayram  | TÃ¼rkÃ§e Instruction       |
| 6    | **alibayram/medgemma (4B)**                | **61.19%**   | 3,794       | Ali Bayram  | Kompakt TÄ±bbi Model      |
| 7    | **Defne-llama3.1-8B**                      | **57.24%**   | 3,549       | AÃ§Ä±k Kaynak | TÃ¼rkÃ§e Llama             |
| 8    | **YTU-CE-Cosmos-Turkish-Llama-8B**         | **54.94%**   | 3,406       | YTÃœ         | Akademik AraÅŸtÄ±rma       |
| 9    | **alibayram/doktorllama3-cosmos**          | **53.15%**   | 3,295       | Ali Bayram  | TÄ±bbi Cosmos             |
| 10   | **Metin-LLaMA-3-8B-Instruct-TR-DPO**       | **52.39%**   | 3,248       | AÃ§Ä±k Kaynak | TÃ¼rkÃ§e DPO               |

```
Model Boyutu vs Performans:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 70B+ Models    â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ 79-84%  â”‚
â”‚ 20-35B Models  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ 70-78%       â”‚
â”‚ 8-15B Models   â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ 50-70%              â”‚
â”‚ <8B Models     â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ 20-50%                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

API vs AÃ§Ä±k Kaynak:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ API Models     â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ 76-84%  â”‚
â”‚ Open Source    â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ 20-79%       â”‚
â”‚ Turkish Fine.  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ 52-74%             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“š Veri Setleri

### ğŸ“¥ Veri Seti Ä°ndirme

```bash
# TÃ¼m veri setlerini indir
python download_datasets.py --all

# Sadece belirli veri setlerini indir
python download_datasets.py --datasets turkish_mmlu

# Hugging Face Hub'dan direkt kullanÄ±m
from datasets import load_dataset

# Ana veri setleri
dataset = load_dataset("alibayram/yapay_zeka_turkce_mmlu_model_cevaplari")
leaderboard = load_dataset("alibayram/yapay_zeka_turkce_mmlu_liderlik_tablosu")
results_by_section = load_dataset("alibayram/yapay_zeka_turkce_mmlu_bolum_sonuclari")
```

### ğŸ“Š Veri Seti Ä°statistikleri

| Veri Seti                         | Boyut           | Format  | Lisans       | DOI              | Son GÃ¼ncelleme |
| --------------------------------- | --------------- | ------- | ------------ | ---------------- | -------------- |
| **Turkish MMLU Model CevaplarÄ±**  | 6,200 soru      | Parquet | CC BY-NC 4.0 | 10.57967/hf/3128 | Temmuz 2025    |
| **Turkish MMLU Liderlik Tablosu** | 60+ model       | Parquet | CC BY-NC 4.0 | -                | Temmuz 2025    |
| **Turkish MMLU BÃ¶lÃ¼m SonuÃ§larÄ±**  | 62 kategori     | Parquet | CC BY-NC 4.0 | -                | Temmuz 2025    |
| **Medical QA Turkish**            | 167,000+ Ã§ift   | JSON    | CC BY-NC 4.0 | -                | Haziran 2025   |
| **Legal NLP Turkish**             | 25,000+ dokÃ¼man | JSON    | CC BY 4.0    | -                | MayÄ±s 2025     |
| **Morphology Tests**              | 15,000+ test    | JSON    | MIT          | -                | Nisan 2025     |

### ğŸ›ï¸ Resmi Hugging Face Veri Setleri

#### ğŸ“ˆ Ana Benchmark Koleksiyonu

1. **[yapay_zeka_turkce_mmlu_model_cevaplari](https://huggingface.co/datasets/alibayram/yapay_zeka_turkce_mmlu_model_cevaplari)**

   - **AÃ§Ä±klama**: 60+ yapay zeka modelinin Turkish MMLU sorularÄ±na verdiÄŸi cevaplar
   - **Ã–zellikler**: 62 kategori, 6,200 soru, gerÃ§ek eÄŸitim sistemi sorularÄ±
   - **Modeller**: GPT-4o, Claude-3.5, Gemini-1.5, Llama-3.1, TÃ¼rkÃ§e Ã¶zel modeller
   - **DOI**: `10.57967/hf/3128`

2. **[yapay_zeka_turkce_mmlu_liderlik_tablosu](https://huggingface.co/datasets/alibayram/yapay_zeka_turkce_mmlu_liderlik_tablosu)**

   - **AÃ§Ä±klama**: Modellerin genel performans sonuÃ§larÄ± ve sÄ±ralama
   - **Metrikler**: BaÅŸarÄ± oranÄ±, doÄŸru cevap sayÄ±sÄ±, toplam sÃ¼re
   - **Format**: DetaylÄ± model bilgileri (family, parameter_size, quantization)

3. **[yapay_zeka_turkce_mmlu_bolum_sonuclari](https://huggingface.co/datasets/alibayram/yapay_zeka_turkce_mmlu_bolum_sonuclari)**
   - **AÃ§Ä±klama**: Modellerin her kategorideki detaylÄ± performansÄ±
   - **Kategoriler**: KPSS, TUS, AUZEF, YKS ve 58+ alt kategori
   - **Analiz**: Kategori bazÄ±nda gÃ¼Ã§lÃ¼/zayÄ±f yÃ¶nler

### ğŸ”„ Veri Seti FormatÄ±

#### Turkish MMLU Ana Veri Seti

```json
{
  "bolum": "KPSS_Genel_KÃ¼ltÃ¼r",
  "soru": "OsmanlÄ± Ä°mparatorluÄŸu'nun kuruluÅŸ tarihi hangi yÃ¼zyÄ±ldÄ±r?",
  "cevap": 1,
  "secenekler": ["13. yÃ¼zyÄ±l", "14. yÃ¼zyÄ±l", "15. yÃ¼zyÄ±l", "16. yÃ¼zyÄ±l"]
}
```

#### Model CevaplarÄ± FormatÄ±

```json
{
  "bolum": "KPSS_Genel_KÃ¼ltÃ¼r",
  "soru": "OsmanlÄ± Ä°mparatorluÄŸu'nun kuruluÅŸ tarihi hangi yÃ¼zyÄ±ldÄ±r?",
  "cevap": 1,
  "secenekler": ["13. yÃ¼zyÄ±l", "14. yÃ¼zyÄ±l", "15. yÃ¼zyÄ±l", "16. yÃ¼zyÄ±l"],
  "gpt-4o_cevap": "B",
  "claude-3-5-sonnet-20240620_cevap": "B) 14. yÃ¼zyÄ±l",
  "gemini-1.5-pro_cevap": "B",
  "llama3.3:latest_cevap": "14. yÃ¼zyÄ±l olarak bilinir, cevap B",
  "ytu-ce-cosmos-Turkish-Llama-8b-DPO-v0-1:latest_cevap": "B"
}
```

#### Liderlik Tablosu FormatÄ±

```json
{
  "model": "gpt-4o",
  "format": "API-Accessed",
  "family": "GPT",
  "parameter_size": "Unknown",
  "quantization_level": "No Quantization",
  "dogru_cevap_sayisi": 5530,
  "basari": 89.2,
  "toplam_sure": 1847.3
}
```

#### Kategori SonuÃ§larÄ± FormatÄ±

```json
{
  "model": "gpt-4o",
  "KPSS_Genel_KÃ¼ltÃ¼r": 125,
  "TUS_TÄ±p": 89,
  "AUZEF_Sosyoloji": 67,
  "YKS_Matematik": 134,
  "ortalama": 89.2
}
```

### ğŸ“‹ Veri Seti Kategorileri (62 Kategori)

#### ğŸ“ EÄŸitim Sistemi SÄ±navlarÄ±

- **KPSS**: Genel KÃ¼ltÃ¼r, Genel Yetenek, EÄŸitim Bilimleri
- **TUS**: TÄ±p UzmanlÄ±k SÄ±navÄ± (15 farklÄ± alan)
- **AUZEF**: AÃ§Ä±k Ã–ÄŸretim FakÃ¼ltesi (25 program)
- **YKS**: Ãœniversite GiriÅŸ SÄ±navÄ± temel konularÄ±

#### ğŸ”¬ Bilim ve Teknoloji

- Matematik, Fizik, Kimya, Biyoloji
- Bilgisayar Bilimleri, MÃ¼hendislik
- Ä°statistik, Astronomi

#### ğŸ“š Sosyal Bilimler

- Tarih, CoÄŸrafya, Sosyoloji, Psikoloji
- Felsefe, Edebiyat, Dil Bilgisi
- Hukuk, Ä°ktisat, Siyaset Bilimi

#### ğŸ¥ UzmanlÄ±k AlanlarÄ±

- TÄ±p ve SaÄŸlÄ±k Bilimleri
- Hukuk ve Adalet
- EÄŸitim ve Pedagoji
- Ä°ÅŸ ve YÃ¶netim

### ğŸ“Š DOI ve AtÄ±f Bilgileri

- **Turkish MMLU Model CevaplarÄ±**: `DOI: 10.57967/hf/3128`
- **Hugging Face Dataset**: [yapay_zeka_turkce_mmlu_model_cevaplari](https://huggingface.co/datasets/alibayram/yapay_zeka_turkce_mmlu_model_cevaplari)
- **Lisans**: CC BY-NC 4.0 (Ticari olmayan kullanÄ±m, atÄ±f gerekli)

---

## ğŸ† Metodoloji

### ğŸ“ DeÄŸerlendirme Metrikleri

#### Temel Metrikler

- **DoÄŸruluk (Accuracy)**: DoÄŸru cevap yÃ¼zdesi
- **F1 Skoru**: Hassasiyet ve hatÄ±rlama dengesi
- **BLEU Skoru**: Ãœretilen metinlerin kalitesi
- **Perplexity**: Dil modelinin karmaÅŸÄ±klÄ±ÄŸÄ±

#### TÃ¼rkÃ§e Ã–zel Metrikler

- **Morfololojik DoÄŸruluk**: Ã‡ekim eklerinin doÄŸru kullanÄ±mÄ±
- **Semantik Benzerlik**: Anlam korunma oranÄ± (`paraphrase-multilingual-mpnet-base-v2`)
- **Tokenizasyon Kalitesi**: Alt-kelime segmentasyon baÅŸarÄ±sÄ±

### ğŸ”¬ DeÄŸerlendirme Metodolojisi

#### ğŸ¯ Cevap DoÄŸrulama SÃ¼reci

```python
def cevap_dogru_mu(dogru_cevap_index, verilen_cevap, secenekler):
    """
    GeliÅŸmiÅŸ cevap doÄŸrulama algoritmasÄ±:
    1. DoÄŸrudan eÅŸleÅŸme kontrolÃ¼ (A, B, C, D, E)
    2. Format toleransÄ± (A:, A), A-, A. gibi)
    3. Anlamsal benzerlik analizi
    """
    harfler = ['A', 'B', 'C', 'D', 'E']
    dogru_harf = harfler[dogru_cevap_index]
    verilen_cevap = verilen_cevap.upper().strip()

    # DoÄŸrudan eÅŸleÅŸme
    if dogru_harf == verilen_cevap:
        return True

    # Format toleransÄ±
    elif len(verilen_cevap) > 1 and verilen_cevap[1] in [" ", ":", ")", "=", "-", "."]:
        return dogru_harf == verilen_cevap[0]

    # Anlamsal benzerlik
    else:
        encoded_cevap = semantic_model.encode([verilen_cevap])
        encoded_secenekler = semantic_model.encode(secenekler)
        similarities = semantic_model.similarity(encoded_cevap, encoded_secenekler)
        return similarities.argmax() == dogru_cevap_index
```

### ğŸ“Š Ä°statistiksel Analiz

- **Bootstrap Ã–rnekleme**: GÃ¼ven aralÄ±klarÄ± hesaplama
- **McNemar Testi**: Model karÅŸÄ±laÅŸtÄ±rmalarÄ±
- **Cohen's Kappa**: DeÄŸerlendirici uyumu
- **Effect Size**: Pratik anlamlÄ±lÄ±k

---

## ğŸ¤ KatkÄ±da Bulunma

### ğŸš€ NasÄ±l KatkÄ±da Bulunurum?

1. **Repo'yu fork edin**
2. **Feature branch oluÅŸturun**: `git checkout -b feature/yeni-ozellik`
3. **DeÄŸiÅŸikliklerinizi commit edin**: `git commit -am 'Yeni Ã¶zellik eklendi'`
4. **Branch'inizi push edin**: `git push origin feature/yeni-ozellik`
5. **Pull Request oluÅŸturun**

### ğŸ“ KatkÄ± TÃ¼rleri

- ğŸ› **Bug RaporlarÄ±**: Hata bildirimleri
- ğŸ’¡ **Ã–zellik Ã–nerileri**: Yeni fikirler
- ğŸ“š **DokÃ¼mantasyon**: Ä°yileÅŸtirmeler
- ğŸ§ª **Test Ekleme**: Yeni test senaryolarÄ±
- ğŸŒ **Ã‡eviri**: DiÄŸer dillere Ã§eviri
- ğŸ“Š **Veri Seti**: Yeni benchmark veri setleri

### ğŸ‘¥ GeliÅŸtirici TopluluÄŸu

- **GitHub Discussions**: Sorular ve tartÄ±ÅŸmalar
- **Weekly Meetings**: HaftalÄ±k toplantÄ±lar (Pazartesi 19:00 (+3 UTC))
- **Code Review**: Peer review sÃ¼reci

---

## ğŸ“ AlÄ±ntÄ±

### ğŸ“š Ana Makale

Bu Ã§alÄ±ÅŸmayÄ± kullanÄ±yorsanÄ±z, lÃ¼tfen resmi arXiv makalemizi alÄ±ntÄ±layÄ±n:

```bibtex
@article{bayram2024setting,
  title={Setting Standards in Turkish NLP: TR-MMLU for Large Language Model Evaluation},
  author={Bayram, M. Ali and Fincan, Ali Arda and GÃ¼mÃ¼ÅŸ, Ahmet Semih and Diri, Banu and YÄ±ldÄ±rÄ±m, SavaÅŸ and AytaÅŸ, Ã–ner},
  journal={arXiv preprint arXiv:2501.00593},
  year={2024},
  url={https://arxiv.org/abs/2501.00593}
}
```

### ğŸ“Š Veri Seti AlÄ±ntÄ±sÄ±

TR-MMLU veri setini kullanÄ±yorsanÄ±z:

```bibtex
@dataset{bayram2024trmmlu_dataset,
  title={TR-MMLU: Turkish Massive Multitask Language Understanding Dataset},
  author={Bayram, M. Ali and Fincan, Ali Arda and GÃ¼mÃ¼ÅŸ, Ahmet Semih},
  year={2024},
  publisher={Hugging Face},
  doi={10.57967/hf/3128},
  url={https://huggingface.co/datasets/alibayram/yapay_zeka_turkce_mmlu_model_cevaplari}
}
```

### ğŸ›ï¸ Hugging Face Koleksiyonu

```bibtex
@misc{trmmlu_collection,
  title={TR-MMLU Benchmark Collection},
  author={Bayram, M. Ali and magibu AI Research Team},
  year={2024},
  howpublished={\url{https://huggingface.co/datasets/alibayram}},
  note={Accessed: \today}
}
```

### ğŸ“ˆ CanlÄ± SonuÃ§lar

```bibtex
@misc{trmmlu_live_results,
  title={TR-MMLU Live Benchmark Results},
  author={magibu AI Research},
  year={2024},
  howpublished={\url{https://magibu.web.app/benchmarks}},
  note={Real-time model performance tracking}
}
```

### ğŸ”— Kaynak BaÄŸlantÄ±larÄ±

- **arXiv Makalesi**: https://arxiv.org/abs/2501.00593
- **Hugging Face Hub**: https://huggingface.co/datasets/alibayram
- **CanlÄ± SonuÃ§lar**: https://magibu.web.app/benchmarks
- **GitHub Repository**: https://github.com/malibayram/llm-tr-benchmarks
- **DOI**: https://doi.org/10.57967/hf/3128

---

## ğŸ“ Ä°letiÅŸim

### ğŸ¢ magibu AI Research Team

- **ğŸŒ Website**: [magibu.web.app](https://magibu.web.app)

### ğŸ‘¨â€ğŸ’» Teknik Destek

- **ğŸ› Issues**: [GitHub Issues](https://github.com/malibayram/llm-tr-benchmarks/issues)
- **ğŸ’¬ Discussions**: [GitHub Discussions](https://github.com/malibayram/llm-tr-benchmarks/discussions)

### ğŸ¤ Ä°ÅŸ Birlikleri

- **Hugging Face**: Model ve dataset hosting
- **Google Research**: Cloud computing destegi
- **NVIDIA**: GPU kaynak destegi

---

## ğŸ“„ Lisans

Bu proje [MIT LisansÄ±](LICENSE) altÄ±nda lisanslanmÄ±ÅŸtÄ±r.

```
MIT License

Copyright (c) 2025 magibu AI Research

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction...
```

### ğŸ“Š Veri Seti LisanslarÄ±

- **Turkish MMLU**: CC BY-SA 4.0
- **Medical QA**: CC BY-NC 4.0 (Ticari olmayan kullanÄ±m)
- **Legal NLP**: CC BY 4.0

---

---

<div align="center">

**ğŸ‡¹ğŸ‡· Setting Standards in Turkish NLP with TR-MMLU! ğŸš€**

[![arXiv Paper](https://img.shields.io/badge/ğŸ“-Read%20Paper-red?style=for-the-badge)](https://arxiv.org/abs/2501.00593) [![Live Results](https://img.shields.io/badge/ğŸ“Š-Live%20Results-green?style=for-the-badge)](https://magibu.web.app/benchmarks) [![Hugging Face](https://img.shields.io/badge/ğŸ¤—-Datasets-orange?style=for-the-badge)](https://huggingface.co/datasets/alibayram)

[â­ Star](https://github.com/malibayram/llm-tr-benchmarks) | [ğŸ”„ Fork](https://github.com/malibayram/llm-tr-benchmarks/fork) | [ğŸ“ Issues](https://github.com/malibayram/llm-tr-benchmarks/issues) | [ğŸ’¬ Discussions](https://github.com/malibayram/llm-tr-benchmarks/discussions)

**Cite our work**: `arxiv:2501.00593` | **Live Benchmark**: `magibu.web.app/benchmarks` | **DOI**: `10.57967/hf/3128`

</div>

---

_Son gÃ¼ncelleme: 28 Temmuz 2025 | TR-MMLU Versiyon: 2.1.0 | arXiv: 2501.00593 | DOI: 10.57967/hf/3128_
